{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-11T10:13:18.028154Z",
     "start_time": "2024-11-11T10:13:18.023021Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T10:11:50.645645Z",
     "start_time": "2024-11-11T10:11:31.767752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def extract_iters(ep):\n",
    "    file_pattern = f'Results/EP{ep}/EP{ep}_Ideal_points_emIRT_Iteration*.csv'\n",
    "\n",
    "    # Use glob to list all files matching the pattern\n",
    "    file_list = glob.glob(file_pattern)\n",
    "\n",
    "    # Initialize an empty list to hold the DataFrames\n",
    "    df_list = []\n",
    "\n",
    "    for file in file_list:\n",
    "        df = pd.read_csv(file)\n",
    "        column = df[f'EPG....EPG{ep}']\n",
    "        names = df[f'MepId....names{ep}']\n",
    "        df = df['d1']\n",
    "\n",
    "        df_list.append(df)\n",
    "\n",
    "    combined_df = pd.concat(df_list, axis=0)\n",
    "\n",
    "    # Calculate the average across the DataFrames\n",
    "    average_df = combined_df.groupby(combined_df.index).mean()\n",
    "    column = column.reset_index(drop=True)\n",
    "    names = names.reset_index(drop=True)\n",
    "    average_df = average_df.reset_index(drop=True)\n",
    "\n",
    "    final_df = pd.concat([names, column, average_df], axis=1)\n",
    "\n",
    "    final_df.columns = ['MepId', 'EPG', 'Average_position']\n",
    "    return final_df\n",
    "\n",
    "\n",
    "avg6 = extract_iters(6)\n",
    "avg7 = extract_iters(7)\n",
    "avg8 = extract_iters(8)\n",
    "avg9 = extract_iters(9)\n",
    "mepinfo6 = pd.read_csv(os.path.join('Cleaned_data', 'EP6_clean_data', 'mep_info_EP_6.csv'))\n",
    "mepinfo7 = pd.read_csv(os.path.join('Cleaned_data', 'EP7_clean_data', 'mep_info_EP_7.csv'))\n",
    "mepinfo8 = pd.read_csv(os.path.join('Cleaned_data', 'EP8_clean_data', 'mep_info_EP_8.csv'))\n",
    "avg7 = avg7.rename(columns={'MepId': 'FullName'})\n",
    "avg8 = avg8.rename(columns={'MepId': 'FullName'})\n",
    "\n",
    "avg7 = pd.merge(avg7, mepinfo7, on='FullName', how='left')\n",
    "avg8 = pd.merge(avg8, mepinfo8, on='FullName', how='left')\n",
    "\n",
    "\n",
    "def load_vote_data(ep):\n",
    "    df = pd.read_csv(os.path.join('Results', f'votes_plotly_{ep}.csv'))\n",
    "    epg_counts = df['MepId'].value_counts()\n",
    "    epg_4_votes = df[df['Vote'] == 4]['MepId'].value_counts()\n",
    "    dataframe = pd.DataFrame()\n",
    "    dataframe['MepId'] = df['MepId'].unique()\n",
    "    proportions = epg_4_votes / epg_counts\n",
    "    dataframe['Proportion'] = proportions\n",
    "    return proportions.reset_index()\n",
    "\n",
    "\n",
    "proportions6 = load_vote_data(6)\n",
    "proportions7 = load_vote_data(7)\n",
    "proportions8 = load_vote_data(8)\n",
    "proportions9 = load_vote_data(9)\n",
    "final6 = pd.merge(proportions6, avg6, on='MepId', how='left')\n",
    "final7 = pd.merge(proportions7, avg7, on='MepId', how='left')\n",
    "final8 = pd.merge(proportions8, avg8, on='MepId', how='left')\n",
    "final9 = pd.merge(proportions9, avg9, on='MepId', how='left')\n",
    "\n"
   ],
   "id": "1e59d7ec3e0a4b4d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T10:13:22.656984Z",
     "start_time": "2024-11-11T10:13:21.029542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "linear7 = final7[['count', 'Average_position', 'Country', 'EPG_x', 'Gender', 'Start', 'Birthday']]\n",
    "\n",
    "# Convert categorical variables into dummy variables\n",
    "linear7 = pd.get_dummies(linear7, columns=['Country', 'EPG_x', 'Gender'])\n",
    "\n",
    "# Function to calculate age based on Start and Birthday columns\n",
    "def get_age(row):\n",
    "    date1 = pd.to_datetime(row['Start'])\n",
    "    date2 = pd.to_datetime(row['Birthday'])\n",
    "    age = relativedelta(date1, date2).years\n",
    "    return age\n",
    "\n",
    "# Apply the age calculation and add it as a new column\n",
    "linear7['Age'] = linear7.apply(get_age, axis=1)\n",
    "\n",
    "# Define the target variable y and drop unnecessary columns\n",
    "y = linear7['count']\n",
    "linear7.drop(['Start', 'Birthday', 'count'], axis=1, inplace=True)\n",
    "\n",
    "# Ensure all data is numeric\n",
    "linear7 = linear7.apply(pd.to_numeric, errors='coerce')\n",
    "y = pd.to_numeric(y, errors='coerce')\n",
    "\n",
    "# Drop or fill any NaN values (fill with zero for simplicity)\n",
    "linear7.fillna(0, inplace=True)\n",
    "y.fillna(0, inplace=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train7, test7, ytrain7, ytest7 = train_test_split(linear7, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to numpy arrays to prevent dtype issues\n",
    "train7 = np.asarray(train7, dtype=float)\n",
    "test7 = np.asarray(test7, dtype=float)\n",
    "ytrain7 = np.asarray(ytrain7, dtype=float)\n",
    "ytest7 = np.asarray(ytest7, dtype=float)\n",
    "\n",
    "# Step 2: Add constant term for intercept\n",
    "train7 = sm.add_constant(train7)\n",
    "test7 = sm.add_constant(test7)\n",
    "\n",
    "# Step 3: Fit the OLS model with robust standard errors\n",
    "# Fit the model on training data\n",
    "model = sm.OLS(ytrain7, train7)\n",
    "robust_model = model.fit(cov_type='HC3')  # Use HC3 for robust standard errors\n",
    "\n",
    "# Step 4: Model Summary\n",
    "# Print the summary to see coefficients and robust standard errors\n",
    "print(robust_model.summary())\n",
    "\n",
    "# Step 5: Predict on Test Set\n",
    "# Make predictions on the test set\n",
    "ypred = robust_model.predict(test7)\n",
    "\n",
    "# Step 6: Evaluate the Model\n",
    "# Calculate Mean Squared Error and R-squared for the test set\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(ytest7, ypred)\n",
    "r2 = r2_score(ytest7, ypred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ],
   "id": "d0e6a2804fc1543a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.119\n",
      "Model:                            OLS   Adj. R-squared:                  0.068\n",
      "Method:                 Least Squares   F-statistic:                     46.56\n",
      "Date:                Mon, 11 Nov 2024   Prob (F-statistic):          2.52e-158\n",
      "Time:                        11:13:22   Log-Likelihood:                 604.69\n",
      "No. Observations:                 682   AIC:                            -1133.\n",
      "Df Residuals:                     644   BIC:                            -961.4\n",
      "Df Model:                          37                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0921      0.014      6.584      0.000       0.065       0.119\n",
      "x1             0.0022      0.007      0.301      0.763      -0.012       0.016\n",
      "x2            -0.0640      0.016     -3.984      0.000      -0.095      -0.033\n",
      "x3            -0.0003      0.033     -0.008      0.993      -0.064       0.064\n",
      "x4            -0.0084      0.021     -0.406      0.685      -0.049       0.032\n",
      "x5            -0.0788      0.008     -9.353      0.000      -0.095      -0.062\n",
      "x6             0.0439      0.037      1.186      0.236      -0.029       0.116\n",
      "x7             0.0066      0.022      0.303      0.762      -0.036       0.049\n",
      "x8            -0.0037      0.014     -0.262      0.793      -0.032       0.024\n",
      "x9            -0.0161      0.022     -0.724      0.469      -0.060       0.027\n",
      "x10            0.0118      0.057      0.207      0.836      -0.100       0.123\n",
      "x11            0.0252      0.013      1.933      0.053      -0.000       0.051\n",
      "x12            0.0043      0.012      0.353      0.724      -0.020       0.028\n",
      "x13            0.0691      0.023      3.013      0.003       0.024       0.114\n",
      "x14            0.0111      0.024      0.463      0.644      -0.036       0.058\n",
      "x15           -0.0357      0.011     -3.161      0.002      -0.058      -0.014\n",
      "x16            0.0474      0.016      2.925      0.003       0.016       0.079\n",
      "x17            0.0359      0.043      0.837      0.403      -0.048       0.120\n",
      "x18            0.0670      0.033      2.016      0.044       0.002       0.132\n",
      "x19           -0.0248      0.016     -1.528      0.127      -0.057       0.007\n",
      "x20            0.0048      0.063      0.076      0.939      -0.120       0.129\n",
      "x21           -0.0299      0.022     -1.351      0.177      -0.073       0.014\n",
      "x22           -0.0087      0.017     -0.519      0.604      -0.041       0.024\n",
      "x23           -0.0039      0.017     -0.234      0.815      -0.036       0.029\n",
      "x24            0.0191      0.019      0.980      0.327      -0.019       0.057\n",
      "x25           -0.0172      0.019     -0.897      0.369      -0.055       0.020\n",
      "x26            0.0078      0.026      0.299      0.765      -0.043       0.059\n",
      "x27            0.0192      0.012      1.558      0.119      -0.005       0.043\n",
      "x28           -0.0213      0.024     -0.897      0.370      -0.068       0.025\n",
      "x29            0.0317      0.019      1.662      0.096      -0.006       0.069\n",
      "x30           -0.0003      0.013     -0.022      0.982      -0.026       0.025\n",
      "x31            0.0139      0.035      0.399      0.690      -0.055       0.082\n",
      "x32            0.0594      0.035      1.700      0.089      -0.009       0.128\n",
      "x33           -0.0160      0.027     -0.602      0.547      -0.068       0.036\n",
      "x34            0.0058      0.026      0.224      0.823      -0.045       0.057\n",
      "x35           -0.0082      0.042     -0.196      0.845      -0.090       0.074\n",
      "x36            0.0422      0.029      1.462      0.144      -0.014       0.099\n",
      "x37           -0.0048      0.018     -0.269      0.788      -0.040       0.030\n",
      "x38            0.0400      0.008      4.964      0.000       0.024       0.056\n",
      "x39            0.0521      0.008      6.624      0.000       0.037       0.067\n",
      "x40           -0.0001      0.000     -0.282      0.778      -0.001       0.001\n",
      "==============================================================================\n",
      "Omnibus:                      220.743   Durbin-Watson:                   1.896\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              779.718\n",
      "Skew:                           1.509   Prob(JB):                    4.86e-170\n",
      "Kurtosis:                       7.282   Cond. No.                     9.74e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
      "[2] The smallest eigenvalue is 1.94e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "Mean Squared Error: 0.0099939895369991\n",
      "R-squared: 0.08847437917770773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleks\\Documents\\GitHub\\EPVoteMonitor\\.venv\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 40, but rank is 38\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T10:14:17.772404Z",
     "start_time": "2024-11-11T10:14:17.704240Z"
    }
   },
   "cell_type": "code",
   "source": "robust_model.summary()",
   "id": "1fa58c036983571c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.119\n",
       "Model:                            OLS   Adj. R-squared:                  0.068\n",
       "Method:                 Least Squares   F-statistic:                     46.56\n",
       "Date:                Mon, 11 Nov 2024   Prob (F-statistic):          2.52e-158\n",
       "Time:                        11:14:17   Log-Likelihood:                 604.69\n",
       "No. Observations:                 682   AIC:                            -1133.\n",
       "Df Residuals:                     644   BIC:                            -961.4\n",
       "Df Model:                          37                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0921      0.014      6.584      0.000       0.065       0.119\n",
       "x1             0.0022      0.007      0.301      0.763      -0.012       0.016\n",
       "x2            -0.0640      0.016     -3.984      0.000      -0.095      -0.033\n",
       "x3            -0.0003      0.033     -0.008      0.993      -0.064       0.064\n",
       "x4            -0.0084      0.021     -0.406      0.685      -0.049       0.032\n",
       "x5            -0.0788      0.008     -9.353      0.000      -0.095      -0.062\n",
       "x6             0.0439      0.037      1.186      0.236      -0.029       0.116\n",
       "x7             0.0066      0.022      0.303      0.762      -0.036       0.049\n",
       "x8            -0.0037      0.014     -0.262      0.793      -0.032       0.024\n",
       "x9            -0.0161      0.022     -0.724      0.469      -0.060       0.027\n",
       "x10            0.0118      0.057      0.207      0.836      -0.100       0.123\n",
       "x11            0.0252      0.013      1.933      0.053      -0.000       0.051\n",
       "x12            0.0043      0.012      0.353      0.724      -0.020       0.028\n",
       "x13            0.0691      0.023      3.013      0.003       0.024       0.114\n",
       "x14            0.0111      0.024      0.463      0.644      -0.036       0.058\n",
       "x15           -0.0357      0.011     -3.161      0.002      -0.058      -0.014\n",
       "x16            0.0474      0.016      2.925      0.003       0.016       0.079\n",
       "x17            0.0359      0.043      0.837      0.403      -0.048       0.120\n",
       "x18            0.0670      0.033      2.016      0.044       0.002       0.132\n",
       "x19           -0.0248      0.016     -1.528      0.127      -0.057       0.007\n",
       "x20            0.0048      0.063      0.076      0.939      -0.120       0.129\n",
       "x21           -0.0299      0.022     -1.351      0.177      -0.073       0.014\n",
       "x22           -0.0087      0.017     -0.519      0.604      -0.041       0.024\n",
       "x23           -0.0039      0.017     -0.234      0.815      -0.036       0.029\n",
       "x24            0.0191      0.019      0.980      0.327      -0.019       0.057\n",
       "x25           -0.0172      0.019     -0.897      0.369      -0.055       0.020\n",
       "x26            0.0078      0.026      0.299      0.765      -0.043       0.059\n",
       "x27            0.0192      0.012      1.558      0.119      -0.005       0.043\n",
       "x28           -0.0213      0.024     -0.897      0.370      -0.068       0.025\n",
       "x29            0.0317      0.019      1.662      0.096      -0.006       0.069\n",
       "x30           -0.0003      0.013     -0.022      0.982      -0.026       0.025\n",
       "x31            0.0139      0.035      0.399      0.690      -0.055       0.082\n",
       "x32            0.0594      0.035      1.700      0.089      -0.009       0.128\n",
       "x33           -0.0160      0.027     -0.602      0.547      -0.068       0.036\n",
       "x34            0.0058      0.026      0.224      0.823      -0.045       0.057\n",
       "x35           -0.0082      0.042     -0.196      0.845      -0.090       0.074\n",
       "x36            0.0422      0.029      1.462      0.144      -0.014       0.099\n",
       "x37           -0.0048      0.018     -0.269      0.788      -0.040       0.030\n",
       "x38            0.0400      0.008      4.964      0.000       0.024       0.056\n",
       "x39            0.0521      0.008      6.624      0.000       0.037       0.067\n",
       "x40           -0.0001      0.000     -0.282      0.778      -0.001       0.001\n",
       "==============================================================================\n",
       "Omnibus:                      220.743   Durbin-Watson:                   1.896\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              779.718\n",
       "Skew:                           1.509   Prob(JB):                    4.86e-170\n",
       "Kurtosis:                       7.282   Cond. No.                     9.74e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "[2] The smallest eigenvalue is 1.94e-28. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ],
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.119</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.068</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   46.56</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 11 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>2.52e-158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:14:17</td>     <th>  Log-Likelihood:    </th> <td>  604.69</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   682</td>      <th>  AIC:               </th> <td>  -1133.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   644</td>      <th>  BIC:               </th> <td>  -961.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    37</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0921</td> <td>    0.014</td> <td>    6.584</td> <td> 0.000</td> <td>    0.065</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0022</td> <td>    0.007</td> <td>    0.301</td> <td> 0.763</td> <td>   -0.012</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0640</td> <td>    0.016</td> <td>   -3.984</td> <td> 0.000</td> <td>   -0.095</td> <td>   -0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0003</td> <td>    0.033</td> <td>   -0.008</td> <td> 0.993</td> <td>   -0.064</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0084</td> <td>    0.021</td> <td>   -0.406</td> <td> 0.685</td> <td>   -0.049</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0788</td> <td>    0.008</td> <td>   -9.353</td> <td> 0.000</td> <td>   -0.095</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0439</td> <td>    0.037</td> <td>    1.186</td> <td> 0.236</td> <td>   -0.029</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0066</td> <td>    0.022</td> <td>    0.303</td> <td> 0.762</td> <td>   -0.036</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.0037</td> <td>    0.014</td> <td>   -0.262</td> <td> 0.793</td> <td>   -0.032</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0161</td> <td>    0.022</td> <td>   -0.724</td> <td> 0.469</td> <td>   -0.060</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.0118</td> <td>    0.057</td> <td>    0.207</td> <td> 0.836</td> <td>   -0.100</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0252</td> <td>    0.013</td> <td>    1.933</td> <td> 0.053</td> <td>   -0.000</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.0043</td> <td>    0.012</td> <td>    0.353</td> <td> 0.724</td> <td>   -0.020</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.0691</td> <td>    0.023</td> <td>    3.013</td> <td> 0.003</td> <td>    0.024</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.0111</td> <td>    0.024</td> <td>    0.463</td> <td> 0.644</td> <td>   -0.036</td> <td>    0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.0357</td> <td>    0.011</td> <td>   -3.161</td> <td> 0.002</td> <td>   -0.058</td> <td>   -0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.0474</td> <td>    0.016</td> <td>    2.925</td> <td> 0.003</td> <td>    0.016</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0359</td> <td>    0.043</td> <td>    0.837</td> <td> 0.403</td> <td>   -0.048</td> <td>    0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.0670</td> <td>    0.033</td> <td>    2.016</td> <td> 0.044</td> <td>    0.002</td> <td>    0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.0248</td> <td>    0.016</td> <td>   -1.528</td> <td> 0.127</td> <td>   -0.057</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.0048</td> <td>    0.063</td> <td>    0.076</td> <td> 0.939</td> <td>   -0.120</td> <td>    0.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>   -0.0299</td> <td>    0.022</td> <td>   -1.351</td> <td> 0.177</td> <td>   -0.073</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   -0.0087</td> <td>    0.017</td> <td>   -0.519</td> <td> 0.604</td> <td>   -0.041</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>   -0.0039</td> <td>    0.017</td> <td>   -0.234</td> <td> 0.815</td> <td>   -0.036</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.0191</td> <td>    0.019</td> <td>    0.980</td> <td> 0.327</td> <td>   -0.019</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>   -0.0172</td> <td>    0.019</td> <td>   -0.897</td> <td> 0.369</td> <td>   -0.055</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.0078</td> <td>    0.026</td> <td>    0.299</td> <td> 0.765</td> <td>   -0.043</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.0192</td> <td>    0.012</td> <td>    1.558</td> <td> 0.119</td> <td>   -0.005</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>   -0.0213</td> <td>    0.024</td> <td>   -0.897</td> <td> 0.370</td> <td>   -0.068</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.0317</td> <td>    0.019</td> <td>    1.662</td> <td> 0.096</td> <td>   -0.006</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>   -0.0003</td> <td>    0.013</td> <td>   -0.022</td> <td> 0.982</td> <td>   -0.026</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>    0.0139</td> <td>    0.035</td> <td>    0.399</td> <td> 0.690</td> <td>   -0.055</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>    0.0594</td> <td>    0.035</td> <td>    1.700</td> <td> 0.089</td> <td>   -0.009</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -0.0160</td> <td>    0.027</td> <td>   -0.602</td> <td> 0.547</td> <td>   -0.068</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    0.0058</td> <td>    0.026</td> <td>    0.224</td> <td> 0.823</td> <td>   -0.045</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>   -0.0082</td> <td>    0.042</td> <td>   -0.196</td> <td> 0.845</td> <td>   -0.090</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>    0.0422</td> <td>    0.029</td> <td>    1.462</td> <td> 0.144</td> <td>   -0.014</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -0.0048</td> <td>    0.018</td> <td>   -0.269</td> <td> 0.788</td> <td>   -0.040</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>    0.0400</td> <td>    0.008</td> <td>    4.964</td> <td> 0.000</td> <td>    0.024</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>    0.0521</td> <td>    0.008</td> <td>    6.624</td> <td> 0.000</td> <td>    0.037</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>   -0.0001</td> <td>    0.000</td> <td>   -0.282</td> <td> 0.778</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>220.743</td> <th>  Durbin-Watson:     </th> <td>   1.896</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 779.718</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.509</td>  <th>  Prob(JB):          </th> <td>4.86e-170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.282</td>  <th>  Cond. No.          </th> <td>9.74e+16</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)<br/>[2] The smallest eigenvalue is 1.94e-28. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.119   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.068   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     46.56   \\\\\n\\textbf{Date:}             & Mon, 11 Nov 2024 & \\textbf{  Prob (F-statistic):} & 2.52e-158   \\\\\n\\textbf{Time:}             &     11:14:17     & \\textbf{  Log-Likelihood:    } &    604.69   \\\\\n\\textbf{No. Observations:} &         682      & \\textbf{  AIC:               } &    -1133.   \\\\\n\\textbf{Df Residuals:}     &         644      & \\textbf{  BIC:               } &    -961.4   \\\\\n\\textbf{Df Model:}         &          37      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &       HC3        & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const} &       0.0921  &        0.014     &     6.584  &         0.000        &        0.065    &        0.119     \\\\\n\\textbf{x1}    &       0.0022  &        0.007     &     0.301  &         0.763        &       -0.012    &        0.016     \\\\\n\\textbf{x2}    &      -0.0640  &        0.016     &    -3.984  &         0.000        &       -0.095    &       -0.033     \\\\\n\\textbf{x3}    &      -0.0003  &        0.033     &    -0.008  &         0.993        &       -0.064    &        0.064     \\\\\n\\textbf{x4}    &      -0.0084  &        0.021     &    -0.406  &         0.685        &       -0.049    &        0.032     \\\\\n\\textbf{x5}    &      -0.0788  &        0.008     &    -9.353  &         0.000        &       -0.095    &       -0.062     \\\\\n\\textbf{x6}    &       0.0439  &        0.037     &     1.186  &         0.236        &       -0.029    &        0.116     \\\\\n\\textbf{x7}    &       0.0066  &        0.022     &     0.303  &         0.762        &       -0.036    &        0.049     \\\\\n\\textbf{x8}    &      -0.0037  &        0.014     &    -0.262  &         0.793        &       -0.032    &        0.024     \\\\\n\\textbf{x9}    &      -0.0161  &        0.022     &    -0.724  &         0.469        &       -0.060    &        0.027     \\\\\n\\textbf{x10}   &       0.0118  &        0.057     &     0.207  &         0.836        &       -0.100    &        0.123     \\\\\n\\textbf{x11}   &       0.0252  &        0.013     &     1.933  &         0.053        &       -0.000    &        0.051     \\\\\n\\textbf{x12}   &       0.0043  &        0.012     &     0.353  &         0.724        &       -0.020    &        0.028     \\\\\n\\textbf{x13}   &       0.0691  &        0.023     &     3.013  &         0.003        &        0.024    &        0.114     \\\\\n\\textbf{x14}   &       0.0111  &        0.024     &     0.463  &         0.644        &       -0.036    &        0.058     \\\\\n\\textbf{x15}   &      -0.0357  &        0.011     &    -3.161  &         0.002        &       -0.058    &       -0.014     \\\\\n\\textbf{x16}   &       0.0474  &        0.016     &     2.925  &         0.003        &        0.016    &        0.079     \\\\\n\\textbf{x17}   &       0.0359  &        0.043     &     0.837  &         0.403        &       -0.048    &        0.120     \\\\\n\\textbf{x18}   &       0.0670  &        0.033     &     2.016  &         0.044        &        0.002    &        0.132     \\\\\n\\textbf{x19}   &      -0.0248  &        0.016     &    -1.528  &         0.127        &       -0.057    &        0.007     \\\\\n\\textbf{x20}   &       0.0048  &        0.063     &     0.076  &         0.939        &       -0.120    &        0.129     \\\\\n\\textbf{x21}   &      -0.0299  &        0.022     &    -1.351  &         0.177        &       -0.073    &        0.014     \\\\\n\\textbf{x22}   &      -0.0087  &        0.017     &    -0.519  &         0.604        &       -0.041    &        0.024     \\\\\n\\textbf{x23}   &      -0.0039  &        0.017     &    -0.234  &         0.815        &       -0.036    &        0.029     \\\\\n\\textbf{x24}   &       0.0191  &        0.019     &     0.980  &         0.327        &       -0.019    &        0.057     \\\\\n\\textbf{x25}   &      -0.0172  &        0.019     &    -0.897  &         0.369        &       -0.055    &        0.020     \\\\\n\\textbf{x26}   &       0.0078  &        0.026     &     0.299  &         0.765        &       -0.043    &        0.059     \\\\\n\\textbf{x27}   &       0.0192  &        0.012     &     1.558  &         0.119        &       -0.005    &        0.043     \\\\\n\\textbf{x28}   &      -0.0213  &        0.024     &    -0.897  &         0.370        &       -0.068    &        0.025     \\\\\n\\textbf{x29}   &       0.0317  &        0.019     &     1.662  &         0.096        &       -0.006    &        0.069     \\\\\n\\textbf{x30}   &      -0.0003  &        0.013     &    -0.022  &         0.982        &       -0.026    &        0.025     \\\\\n\\textbf{x31}   &       0.0139  &        0.035     &     0.399  &         0.690        &       -0.055    &        0.082     \\\\\n\\textbf{x32}   &       0.0594  &        0.035     &     1.700  &         0.089        &       -0.009    &        0.128     \\\\\n\\textbf{x33}   &      -0.0160  &        0.027     &    -0.602  &         0.547        &       -0.068    &        0.036     \\\\\n\\textbf{x34}   &       0.0058  &        0.026     &     0.224  &         0.823        &       -0.045    &        0.057     \\\\\n\\textbf{x35}   &      -0.0082  &        0.042     &    -0.196  &         0.845        &       -0.090    &        0.074     \\\\\n\\textbf{x36}   &       0.0422  &        0.029     &     1.462  &         0.144        &       -0.014    &        0.099     \\\\\n\\textbf{x37}   &      -0.0048  &        0.018     &    -0.269  &         0.788        &       -0.040    &        0.030     \\\\\n\\textbf{x38}   &       0.0400  &        0.008     &     4.964  &         0.000        &        0.024    &        0.056     \\\\\n\\textbf{x39}   &       0.0521  &        0.008     &     6.624  &         0.000        &        0.037    &        0.067     \\\\\n\\textbf{x40}   &      -0.0001  &        0.000     &    -0.282  &         0.778        &       -0.001    &        0.001     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 220.743 & \\textbf{  Durbin-Watson:     } &     1.896  \\\\\n\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &   779.718  \\\\\n\\textbf{Skew:}          &   1.509 & \\textbf{  Prob(JB):          } & 4.86e-170  \\\\\n\\textbf{Kurtosis:}      &   7.282 & \\textbf{  Cond. No.          } &  9.74e+16  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors are heteroscedasticity robust (HC3) \\newline\n [2] The smallest eigenvalue is 1.94e-28. This might indicate that there are \\newline\n strong multicollinearity problems or that the design matrix is singular."
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
